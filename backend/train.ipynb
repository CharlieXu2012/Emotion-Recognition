{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/IAmSuyogJadhav/Emotion-Recognition/blob/master/train.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "W3BGoF31v316",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "a16e6631-bf99-4823-b999-041379fea174"
      },
      "cell_type": "code",
      "source": [
        "# For Google Colab\n",
        "# Uncomment following code for mounting Google Drive\n",
        "\n",
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive\n",
        "# %cd drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P6u_ny90Eto-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XppkUWntEtpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c03a466-d63c-4df4-c62a-2767c437e096"
      },
      "cell_type": "code",
      "source": [
        "# For Google Colab\n",
        "# %cd ML/Emotion-Recognition"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/ML/Emotion-Recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3W32OZxPxvA_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Specify the image size here\n",
        "img_size = 25 #@param {type:\"slider\", min:10, max:50, step:1}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkHn4jZ6xnkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UNCOMMENT FOLLOWING CODE TO GENERATE TRAIN DATA OF REQUIRED SIZE\n",
        "\n",
        "\n",
        "# import os\n",
        "# train_list = os.listdir(\"./images_new\")\n",
        "# sample_img = plt.imread('./images_new/' + train_list[2])\n",
        "# print(sample_img.shape)\n",
        "# plt.imshow(sample_img)\n",
        "\n",
        "# img_size = 25\n",
        "# train = np.zeros((len(train_list), img_size, img_size))\n",
        "\n",
        "# print(train.shape)\n",
        "# train_labels = np.zeros(len(train_list))\n",
        "\n",
        "# print(train_labels.shape)\n",
        "\n",
        "# labels = pd.read_csv('labels.csv')\n",
        "# to_int = {\n",
        "#     'anger': 0,\n",
        "#     'contempt': 1,\n",
        "#     'disgust': 2,\n",
        "#     'fear': 3,\n",
        "#     'happiness': 4,\n",
        "#     'neutral': 5,\n",
        "#     'sad': 6,\n",
        "#     'sadness': 7,\n",
        "#     'surprise':8   \n",
        "# }\n",
        "\n",
        "# from skimage import io\n",
        "# from skimage.transform import resize\n",
        "# np.random.shuffle(train_list)\n",
        "# # j=0\n",
        "# j = 7588\n",
        "# # for i in range(len(train_list)):\n",
        "# for i in range(7610, len(train_list)):\n",
        "#     path = train_list[i]\n",
        "#     print('%d\\t' % (i) if i%100 else '\\r', end=' ')\n",
        "#     img = resize(io.imread('./images_new/' + path), (img_size, img_size))\n",
        "#     try:    \n",
        "#         label = labels[labels.image == path].emotion.values[0]\n",
        "#         train_labels[j] = to_int[label]\n",
        "#         train[j] = img\n",
        "#         j += 1\n",
        "#     except:\n",
        "#         print(\"Failed: i=%d\"%i)\n",
        "#         pass\n",
        "      \n",
        "# train1 = train[:j]\n",
        "# train_labels1 = train_labels[:j]\n",
        "# np.save('train_%dx%d' % (img_size, img_size), train1)\n",
        "# np.save('train_labels_%dx%d' % (img_size, img_size, train_labels1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdPIVUl8jOQj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Choose Image Size to load { form-width: \"10%\", display-mode: \"both\" }\n",
        "size = \"25x25\" #@param [\"25x25\", \"50x50\"]\n",
        "\n",
        "\n",
        "train = np.load('train_{}.npy'.format(size))\n",
        "train = train.reshape(tuple(list(train.shape) + [1])) # reshaping to adjust in conv layer.\n",
        "train_labels = np.load('train_labels_{}.npy'.format(size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7xuf7pDEtrr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras import layers as ll\n",
        "from keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7XOityuix5Qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "8ecec712-fe1c-4063-c1d8-3f427d7c6f64"
      },
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "          rotation_range=15,\n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          zoom_range = 0.1,\n",
        "          horizontal_flip=True,     \n",
        ")\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x=train, y=train_labels, batch_size=2, \n",
        "                          save_to_dir='augmented', save_format='jpeg'):\n",
        "  i+=1\n",
        "  if i > 20:\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2bda613e329b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m for batch in datagen.flow(x=train, y=train_labels, batch_size=2, \n\u001b[0;32m---> 12\u001b[0;31m                           save_to_dir='augmented', save_format='jpeg'):\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                                                   \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                                                   format=self.save_format)\n\u001b[0;32m-> 1171\u001b[0;31m                 \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1723\u001b[0m             \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m             \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'augmented/_3133_1772.jpeg'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Zxy9SPNPMOcq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Adjust hyper parameters { display-mode: \"form\" }\n",
        "alpha = 0.3 #@param {type:\"number\"}\n",
        "pool_size = 2 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "dropout = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "l2_regularization = 0.2 #@param {type:\"number\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vu7nbLdoEtsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_size = train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ll.InputLayer([img_size, img_size, 1]))\n",
        "\n",
        "model.add(ll.Conv2D(filters=16, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.Conv2D(filters=16, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.MaxPool2D(pool_size=(pool_size,pool_size)))\n",
        "\n",
        "model.add(ll.Dropout(dropout))\n",
        "\n",
        "model.add(ll.Conv2D(filters=32, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.Conv2D(filters=32, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.MaxPool2D(pool_size=(pool_size,pool_size)))\n",
        "\n",
        "model.add(ll.Dropout(dropout))\n",
        "\n",
        "model.add(ll.Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "model.add(keras.layers.LeakyReLU(alpha=alpha))\n",
        "model.add(ll.MaxPool2D(pool_size=(pool_size,pool_size)))\n",
        "\n",
        "model.add(ll.Flatten())\n",
        "\n",
        "# model.add(ll.Dense(256, activation='elu', kernel_regularizer=regularizers.l2(l2_regularization)))\n",
        "model.add(ll.Dense(256, activation='tanh', kernel_regularizer=regularizers.l2(l2_regularization)))\n",
        "model.add(ll.Dense(9, activation=\"softmax\"))\n",
        "\n",
        "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SFaS3rXEtsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "outputId": "be94ec12-3bef-4404-8d6a-0f12e7b18aa4"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        (None, 25, 25, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 25, 25, 16)        160       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_99 (LeakyReLU)   (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 25, 25, 16)        2320      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_100 (LeakyReLU)  (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 12, 12, 32)        4640      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_101 (LeakyReLU)  (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 12, 12, 32)        9248      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_102 (LeakyReLU)  (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 6, 6, 64)          18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_103 (LeakyReLU)  (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_104 (LeakyReLU)  (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 256)               295168    \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 9)                 2313      \n",
            "=================================================================\n",
            "Total params: 406,201\n",
            "Trainable params: 406,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BN9t7DoeLobD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Adjust training parameters { vertical-output: true, form-width: \"10%\", display-mode: \"form\" }\n",
        "epochs = 50 #@param {type:\"number\"}\n",
        "train_test_split = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ta6zohWdEtsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1855
        },
        "outputId": "b53ba376-5ea6-4024-a0b4-f5ac89e70a84"
      },
      "cell_type": "code",
      "source": [
        "labels_new = to_categorical(train_labels)\n",
        "model.fit(train[:int(train_test_split*train.shape[0])], labels_new[:int(train_test_split*train.shape[0])], validation_data = [train[int(train_test_split*train.shape[0]):], labels_new[int(train_test_split*train.shape[0]):]], epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10204 samples, validate on 2552 samples\n",
            "Epoch 1/50\n",
            "10204/10204 [==============================] - 6s 596us/step - loss: 0.2817 - acc: 0.9369 - val_loss: 0.3916 - val_acc: 0.9193\n",
            "Epoch 2/50\n",
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2980 - acc: 0.9338 - val_loss: 0.3726 - val_acc: 0.9220\n",
            "Epoch 3/50\n",
            "10204/10204 [==============================] - 6s 604us/step - loss: 0.2874 - acc: 0.9366 - val_loss: 0.3957 - val_acc: 0.9220\n",
            "Epoch 4/50\n",
            " 1568/10204 [===>..........................] - ETA: 4s - loss: 0.3063 - acc: 0.9311"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 600us/step - loss: 0.2814 - acc: 0.9375 - val_loss: 0.3749 - val_acc: 0.9185\n",
            "Epoch 5/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2797 - acc: 0.9366 - val_loss: 0.4004 - val_acc: 0.9228\n",
            "Epoch 6/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2706 - acc: 0.9404 - val_loss: 0.3924 - val_acc: 0.9271\n",
            "Epoch 7/50\n",
            " 5760/10204 [===============>..............] - ETA: 2s - loss: 0.2695 - acc: 0.9406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 586us/step - loss: 0.2710 - acc: 0.9450 - val_loss: 0.4079 - val_acc: 0.9240\n",
            "Epoch 9/50\n",
            "10204/10204 [==============================] - 6s 585us/step - loss: 0.2683 - acc: 0.9402 - val_loss: 0.3779 - val_acc: 0.9252\n",
            "Epoch 10/50\n",
            "10204/10204 [==============================] - 6s 597us/step - loss: 0.2794 - acc: 0.9417 - val_loss: 0.4081 - val_acc: 0.9267\n",
            "Epoch 11/50\n",
            " 6784/10204 [==================>...........] - ETA: 1s - loss: 0.2601 - acc: 0.9449"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 590us/step - loss: 0.2598 - acc: 0.9433 - val_loss: 0.3859 - val_acc: 0.9295\n",
            "Epoch 12/50\n",
            "10204/10204 [==============================] - 6s 595us/step - loss: 0.2625 - acc: 0.9441 - val_loss: 0.4048 - val_acc: 0.9201\n",
            "Epoch 13/50\n",
            "10204/10204 [==============================] - 6s 596us/step - loss: 0.2775 - acc: 0.9439 - val_loss: 0.4258 - val_acc: 0.9287\n",
            "Epoch 14/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2911 - acc: 0.9452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 593us/step - loss: 0.2811 - acc: 0.9451 - val_loss: 0.3788 - val_acc: 0.9314\n",
            "Epoch 15/50\n",
            "10204/10204 [==============================] - 6s 597us/step - loss: 0.2375 - acc: 0.9498 - val_loss: 0.3903 - val_acc: 0.9291\n",
            "Epoch 16/50\n",
            "10204/10204 [==============================] - 6s 601us/step - loss: 0.2494 - acc: 0.9482 - val_loss: 0.3857 - val_acc: 0.9318\n",
            "Epoch 17/50\n",
            " 6496/10204 [==================>...........] - ETA: 2s - loss: 0.2357 - acc: 0.9514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 594us/step - loss: 0.2508 - acc: 0.9512 - val_loss: 0.3880 - val_acc: 0.9295\n",
            "Epoch 18/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.3207 - acc: 0.9456 - val_loss: 0.3641 - val_acc: 0.9342\n",
            "Epoch 19/50\n",
            "10204/10204 [==============================] - 6s 600us/step - loss: 0.2420 - acc: 0.9484 - val_loss: 0.3812 - val_acc: 0.9338\n",
            "Epoch 20/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2442 - acc: 0.9471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2540 - acc: 0.9457 - val_loss: 0.3747 - val_acc: 0.9326\n",
            "Epoch 21/50\n",
            "10204/10204 [==============================] - 6s 590us/step - loss: 0.2445 - acc: 0.9511 - val_loss: 0.4107 - val_acc: 0.9299\n",
            "Epoch 22/50\n",
            "10204/10204 [==============================] - 6s 594us/step - loss: 0.2434 - acc: 0.9498 - val_loss: 0.3905 - val_acc: 0.9310\n",
            "Epoch 23/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2202 - acc: 0.9568"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 597us/step - loss: 0.2312 - acc: 0.9547 - val_loss: 0.4060 - val_acc: 0.9287\n",
            "Epoch 24/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2565 - acc: 0.9502 - val_loss: 0.3742 - val_acc: 0.9283\n",
            "Epoch 25/50\n",
            "10204/10204 [==============================] - 6s 596us/step - loss: 0.2594 - acc: 0.9511 - val_loss: 0.3725 - val_acc: 0.9314\n",
            "Epoch 26/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2292 - acc: 0.9551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 592us/step - loss: 0.2443 - acc: 0.9514 - val_loss: 0.3722 - val_acc: 0.9326\n",
            "Epoch 27/50\n",
            "10204/10204 [==============================] - 6s 596us/step - loss: 0.2368 - acc: 0.9521 - val_loss: 0.4398 - val_acc: 0.9330\n",
            "Epoch 28/50\n",
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2349 - acc: 0.9541 - val_loss: 0.3950 - val_acc: 0.9342\n",
            "Epoch 29/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2295 - acc: 0.9578"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 592us/step - loss: 0.2368 - acc: 0.9563 - val_loss: 0.4340 - val_acc: 0.9393\n",
            "Epoch 30/50\n",
            "10204/10204 [==============================] - 6s 600us/step - loss: 0.2491 - acc: 0.9559 - val_loss: 0.3998 - val_acc: 0.9361\n",
            "Epoch 31/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2517 - acc: 0.9545 - val_loss: 0.3708 - val_acc: 0.9322\n",
            "Epoch 32/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2362 - acc: 0.9561"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2315 - acc: 0.9560 - val_loss: 0.3982 - val_acc: 0.9342\n",
            "Epoch 33/50\n",
            "10204/10204 [==============================] - 6s 590us/step - loss: 0.2164 - acc: 0.9617 - val_loss: 0.4017 - val_acc: 0.9310\n",
            "Epoch 34/50\n",
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2414 - acc: 0.9568 - val_loss: 0.3874 - val_acc: 0.9334\n",
            "Epoch 35/50\n",
            " 6560/10204 [==================>...........] - ETA: 2s - loss: 0.2340 - acc: 0.9607"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 593us/step - loss: 0.2386 - acc: 0.9595 - val_loss: 0.3952 - val_acc: 0.9377\n",
            "Epoch 36/50\n",
            "10204/10204 [==============================] - 6s 601us/step - loss: 0.2419 - acc: 0.9576 - val_loss: 0.4497 - val_acc: 0.9291\n",
            "Epoch 37/50\n",
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2265 - acc: 0.9614 - val_loss: 0.4275 - val_acc: 0.9353\n",
            "Epoch 38/50\n",
            " 6464/10204 [==================>...........] - ETA: 2s - loss: 0.2190 - acc: 0.9613"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 599us/step - loss: 0.2265 - acc: 0.9599 - val_loss: 0.3924 - val_acc: 0.9385\n",
            "Epoch 39/50\n",
            "10204/10204 [==============================] - 6s 607us/step - loss: 0.2252 - acc: 0.9576 - val_loss: 0.4145 - val_acc: 0.9361\n",
            "Epoch 40/50\n",
            "10204/10204 [==============================] - 6s 603us/step - loss: 0.2319 - acc: 0.9615 - val_loss: 0.3989 - val_acc: 0.9385\n",
            "Epoch 41/50\n",
            " 6560/10204 [==================>...........] - ETA: 2s - loss: 0.2123 - acc: 0.9630"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 597us/step - loss: 0.2203 - acc: 0.9617 - val_loss: 0.4152 - val_acc: 0.9357\n",
            "Epoch 42/50\n",
            "10204/10204 [==============================] - 6s 604us/step - loss: 0.2184 - acc: 0.9647 - val_loss: 0.4372 - val_acc: 0.9381\n",
            "Epoch 43/50\n",
            "10204/10204 [==============================] - 6s 600us/step - loss: 0.2190 - acc: 0.9642 - val_loss: 0.4316 - val_acc: 0.9275\n",
            "Epoch 44/50\n",
            " 6496/10204 [==================>...........] - ETA: 2s - loss: 0.2326 - acc: 0.9623"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 603us/step - loss: 0.2318 - acc: 0.9625 - val_loss: 0.4345 - val_acc: 0.9389\n",
            "Epoch 45/50\n",
            "10204/10204 [==============================] - 6s 603us/step - loss: 0.2215 - acc: 0.9605 - val_loss: 0.4509 - val_acc: 0.9400\n",
            "Epoch 46/50\n",
            "10204/10204 [==============================] - 6s 601us/step - loss: 0.2491 - acc: 0.9626 - val_loss: 0.4174 - val_acc: 0.9338\n",
            "Epoch 47/50\n",
            " 6496/10204 [==================>...........] - ETA: 2s - loss: 0.1969 - acc: 0.9663"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 602us/step - loss: 0.2019 - acc: 0.9656 - val_loss: 0.4461 - val_acc: 0.9408\n",
            "Epoch 48/50\n",
            "10204/10204 [==============================] - 6s 601us/step - loss: 0.2318 - acc: 0.9617 - val_loss: 0.3924 - val_acc: 0.9412\n",
            "Epoch 49/50\n",
            "10204/10204 [==============================] - 6s 593us/step - loss: 0.1996 - acc: 0.9677 - val_loss: 0.3821 - val_acc: 0.9412\n",
            "Epoch 50/50\n",
            " 6656/10204 [==================>...........] - ETA: 2s - loss: 0.2110 - acc: 0.9630"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10204/10204 [==============================] - 6s 598us/step - loss: 0.2002 - acc: 0.9666 - val_loss: 0.4179 - val_acc: 0.9416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b96a2a9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "4JOve81WEtte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b3777106-0627-4019-ecfa-c540178a270d"
      },
      "cell_type": "code",
      "source": [
        "with open('./models/model%0.2f.json' % (100*model.evaluate(train[int(0.8*train.shape[0]):], labels_new[int(0.8*train.shape[0]):])[1]), 'w') as model_json:\n",
        "    model_json.write(model.to_json())\n",
        "model.save_weights('./models/weights%0.2f.h5' % (100*model.evaluate(train[int(0.8*train.shape[0]):], labels_new[int(0.8*train.shape[0]):])[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2552/2552 [==============================] - 0s 152us/step\n",
            "2552/2552 [==============================] - 0s 160us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q7DNbClEEttw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Z9-z-9CEtt3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
